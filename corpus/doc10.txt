Automatic text summarization aims to produce a concise and coherent summary of a larger body of text, preserving key ideas while removing redundancy. Early systems used extraction or compression techniques tailored for specific text domains. Current approaches often leverage supervised machine learning and, more recently, neural network models to generate abstractive summaries. Despite progress, summarization remains a challenging problem due to its inherent difficulty in balancing informativeness and readability. In this survey, we review key developments from early extractive methods to modern neural approaches and outline trends and challenges for the future, including contextual understanding, discourse modeling, and evaluation metrics.
