Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self‑driving vehicles, and military which have direct impact on human lives. However, the black‑box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high‑quality interpretable, intuitive, human‑understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work.
